Are you able to hear me? Are you on mute? Hello? Hey, Eldon, how are you?
I'm good. Thank you.
Thank you for joining. Let's wait for two more minutes and then we can get started. Thank you, everyone, for joining this week's clubhouse meet. So in this week we are going to discuss about collaboration in performance testing. So the guest speaker is Eldar. So before we jump into the discussion, I'd like to give a shout out to our sponsor, Red Lane 13. So if you want to run a very high scale load testing, please check it out. Redlane 13. Com where you can scale up your test using JMeter and new infrastructure. And before we again go into the discussion, a couple of industry updates. Last week, a Load Runner has released the next version, 2021 or to release. So if you are working on Load Runner products, then please update your Load Runner Dev Web, true client protocols, et cetera. So this release, they support Apple M one Arm support for Devop protocols. That's one of the main feature in this release. And also Gremlin has released the Advanced certification. So please check it out my Lincoln Post. So there are 30 questions and there is a video tutorial and then documentation. So if you go through those steps, you can easily clear the certification. So it is completely free and Neollord Tricent is allowing people to sign up for the beta products. So again, I have posted a couple of updates in my LinkedIn feed, so please check it out if you are interested in testing the Near Load tool, so that's it from the industry news. So now let us go to this week's topic collaboration performance listing. Hi, Eldard.
Hey, Navin, how are you? I just want to make sure.
Do you hear me? Well, yes, Lord and clear. Awesome.
Well, of course, things change. Yeah, that was fun to do some testing in production.
That's right.
Yes.
I often run production testing mainly before Black Friday and all. Yeah, it's fun to test in production.
Yeah, it is. It's. But it's fun. Okay. So I'll start with probably a short introduction to who I am and what I've been going through in the industry and stuff. So my name is Eldarussman. I've been an automation engineer in general for twelve years. My first job was in a low level networking company. And this is where I really started to see what performance really means, because do you hear me? Well, by the way, because I get some notifications here and there.
Yeah. Thanks a lot for the introduction.
Yeah, I can hear. I think there is some lag, is there?
I guess.
Yeah. Delay. Some things are not as performant as our application.
Probably that's correct.
Yes.
Before we again see, I just give a quick note about recording. So this session is being recorded. It will be available in my YouTube channel once the session is done. So please check it out. Youtube. Comcueinsights. Yes. Please continue.
All right.
So.
Back in the day, when I worked for this low level company, we did low level networking. So I got introduced to crazy stuff like preambles and interframe gaps, things that in the layer two types of performance. And then when I started to do high level performance testing. And this is what I've been doing for the last five years or so. Now I start to face other challenges, which is the extremely high scale that high level applications are supposed to handle, like tens or sometimes even hundreds of thousands of users. So the approach is totally different. And one of the things that I noticed is that there are some approaches that can help you out in your efforts. And this is what we talk about. One of these things that can help you is to collaborate to get more of the other team members involved in your low testing efforts. That's pretty much what we are talking about. Is it something that you relate to? Is it something that you have experience in any way, something you want to share all the time?
All my projects, there are always some challenges, mainly in communicating, collaborating with other team, particularly if you have multiple vendors working in a team.
Right.
So we'll have always some kind of barriers. So there are some particular protocol we have to follow. So based on my inputs from the management and from the client side. So we always tend to follow some kind of process in each client. So it varies depends on to whom you are working and also which level you are reporting.
Right.
In my case, in my early career, of course, I cannot directly skip.
Right.
I cannot directly go to the manager level and report. So I have to report to my team lead. Then team lead will take some actions again. He will report to the development manager. So the chain of command.
Right.
So it is always two to three level up in my early career. But right now, when you progress further.
Right.
So it's kind of easy to interact. You can talk to CTO, or you can talk to the architect level directly.
Right.
So when your career progresses, it is easy to communicate. But of course, if you are in an early career, you need to always follow some kind of protocol we can discuss and elaborate when we go further. So these are some of the main challenges I have faced when I start my career in performance testing.
Yeah. I agree that when you have if you imagine this T shaped skill set of a product team, you have a DBA, for example, specializing in DB stuff. He's really he or she are really good at indexing and engines, data engines and stuff like that. They know a thing to do about back end, they know a thing to do about Kubernetes and DevOps and stuff. But their main expertise is database, and then everybody who's doing us today, the performance engineers. You guys are probably familiar to databases to some degree and to the DevOps culture and other stuff. But your main focus, your main field of expertise is performance testing.
Right. So.
This is the T shaped skill set you're bounced out. You're good at some stuff, but you have one area where you dominate. You're really good. So what it leads to is that very often the low testing efforts are centralized because you are the expert. You happens to centralize either you want to or you don't. But you happens to centralize the execution and the analysis on your own.
Okay.
So you're basically execute the Lotus when you are asked to or when you feel like it doesn't really matter what is the trigger. So you execute the Lotus. You are the only one who execute them, and you are the only one who analyze them. So you look at the data, you look at the results, you look at some anomalies and stuff like that, and then you report. And this is what I refer to as the centralized model of performance testing. I think it's flawed in a way, because first of all, the testing cycles tend to be slow. It takes longer time to test because you wait for changes to accumulate, and because you wait for these changes to accumulate. And then you execute the Lotus when they fail, it's more difficult to pinpoint why they failed. Okay. To do a root cause analysis, it becomes more difficult. So one thing that I've experimented with in my current job is the decentralized model. I tried it with several teams already in several projects, and I was really amazed to see how the two are different because I did both of them at the same time. In some projects, we still did the centralized model. And in other projects, we did the decentralized model, where in the decentralized model, the DBA, for example, can take initiative and run the test by themselves.
Okay.
So they did some changes. They deployed the changes to the testing environment, and then they execute the loads. Of course, there is also the pipelines and stuff, but beyond the pipeline, there is also an Explorer exploration. You explore how your changes impact performance. So the experience that I had when I had some of projects carried out in the centralized model and other projects carried out in the decentralized model, I experienced a much shorter testing cycles. In the decentralized model, I experienced a better modeling of the workload. If you remember, you had to talk here with Nicole about realistic load testing. So a workload model is part of that. And now when you have more people collaborating with you, you're more likely or just to put it in a more negative sense, you are less likely to come up with unrealistic workload models because you have people giving you a counter for your thoughts and your ideas. So I noticed that this decentralized model tends to produce higher productivity and it tends to bring more ideas to the table. You have more ideas, you have a more prolific ecosystem or Echo Chamber of ideas that compete with one another. And when you are engaged in an honest discussion, an open discussion with your colleagues, you're more likely to have better chances that the more suitable ideas would proliferate and the less suitable ideas would diminish. It would not be used anymore. So this is one of the things that I have experienced that it's better to take the execution and analysis of low tests and delegate them to the other stakeholders, like the DBA and the back end developer and the Devil's engineers, and it can produce a more mutually beneficial outcome in my experience.
Yeah.
Okay.
Thanks in that. So let me go back little couple of minutes before. So when you mentioned the T shirt would learn, right. Can you please throw some limelight about what is T shaped learner and how we can be a T shaped learner? So any inputs on that? Well.
Learning is a skill. It's something I really believe in, that learning new topics is a skill. And I think that the more you experience different fields of automation. And I think that low test or performance testing in general does fall into the category of automation. The more you have a chance to explore them. I think the more well rounded you are because you start to touch other stuff. Personally, I do performance testing. I also do functional testing. I also do robotic process automation. And I've also experienced low level programming in a way because we experiment with some protocols that the only way to approach them is through low level programming. Unfortunately. So I think that the more you start challenging yourself with new ideas, you learn how to learn. I think this is the best approach that has worked for me, but of course, I'm well aware that people vary in their learning styles, so it might be a little bit different for others. But I think that practicing how to learn new ideas, having open discussion, being willing to change your mind. And let me give you an example when you have Leandro here on your channel, I think it was like six or eight weeks ago. I think so. I argued that load testing is almost entirely exploratory, and Leandro corrected me on that. He said no, there is some repetitive part. So when you leave your ego out and you are willing to correct your views according to the evidence, this is how you create a well balanced body of knowledge.
I agree.
Yes. Correct.
Now let's talk about that decentralized part. So when we adopt that decentralized framework in performance sustain, so can do whatever he wants.
Correct.
So he has a freedom to do whatever tests he wants to carry out in the environment. So that leads to some kind of chaos, correct. So how do we handle that?
Great question. So first of all, we need to tell if you want to run on a real production life environment. So you have let's say your normal production environment is like at eight pods of Kubernetes and some two load balancers or whatever. Now the question is, do you really need all of that to execute your load test? That's the first thing you need to answer for your project. And if it does, if that's the case, if you have so many cloud native stuff in your application, then you're probably going to have to duplicate your low testing environment. So you have low test one and low test two and low test three. It could be costly, of course, could come out of the cost that you need to maintain all these environments. But this is just one solution. Another solution is that the testers would have to coordinate their efforts. So let's say you have, like, a slack channel for all of you and you cooperate with one another. Hey, I'm running the low test now. And if you use one of these low testing platforms and there are many of them, I think that in the last five years, we have experienced a boom of such products. Great products, very cost efficient products. I think the field has become increasingly competitive in the last five years or so. If you use one of these, you could also use the usually when you use these platforms and you run a test, you have a test ID.
Right.
So you can actually declare, hey, this is the test I'm running now. This is ID 1234. Look at it and see whenever it ends. And this is when the environment is free for you to run. So this is one of the things that you want to do. You want to handle the communication in between the different stakeholders, and also you could run them locally. You can run them on your own environment to see if there is any performance issues already occurring there. I think there was an article I don't remember who wrote it. So whoever wrote it big shout out to you. And I really apologize for not remembering who you are, your name, but to do performance testing with one user, because if your application is not performant on one user, it's not going to be performed on any user. So again, the same idea that if you run it on your own local machine and you start to see problems if you ruled out the local machine problems, if you ruled out that you have other application running on your own local PC, and you can do that very easily when it's under your own control. So you can pretty much do that in this fashion.
So even my today's job we communicate using slack. So whenever I want to about to start a test, I just post a message and someone from Dev team or whoever the team I'm working, they just put some likes or some comment. Then only I will start the test in Jenkins, so it will give some acknowledgement. Then we carry out. Then we share the results. So everything is automated, mostly automated. That's the way every team is different.
Right.
My team uses Slack and other teams. They might use a different communication platform, but collaborating like this helps us to streamline the process.
Yeah, exactly. I think that in the end, there are plenty of tools for collaboration teams or slack. I think that the human factor is the most important. When you have people who are devoted and are willing to communicate, the tools are only as good as the people using them. So I think first of all, the most important thing to practice is good communication, good interpersonal relationship. And then everything just follows.
Correct. Okay. When it comes to performance testing aspect, when it comes to scripting or when it comes to the requirements gathering or epic or story creation space. So how does the collaboration work? Decent racer frameworks works with architects or DevOps guys. So technical aspect.
I'm so happy to ask this question. I'm so happy to ask this question because there's the notion that the worst mistake that you're going to make in every project is in the first five minutes. Correct the notion. And it's true. Unfortunately, you have to constantly talk to all of your stakeholders. There's lots of mentoring going on there. So in the first phases, I think that you first need to get a look at the architecture and you as a performance engineer, you're supposed to know what kind of things to look at. For example, how many asynchronous events are going on in the system, right? In the old days, like ten years ago or even longer, you send a request, you have a post request, the server handles the request, send you a response, and that's it. But today doesn't work out like that at all. Today you send a request, the server gets the request, the request or the metadata or whatever the request contains is being stored somewhere in some cache or some queue. And then it was queued in this stash and the server returns a response. And then there is background around processing for that data that the server queued and queued.
Right.
So this is some kind of asynchronous processing, and then you have some machine learning algorithm or whatever your business requires. So when you have these asynchronous events, measuring the latency of request response is not enough. It's not going to cut it. So this is just one example of the things that you can look at when you design a low test. I think that decentralized model, and it's counterintuitive because if you decentralize things, people just do whatever they want. But it's not true. When you decentralize things, people have a greater incentive to cooperate because they know what's on the line. They know what's in stake. So in the first phases, you do a lot of gathering, you do a lot of thinking, a lot of brainstorming. You do a workload model, you start to get a feeling of how load is going to be generated. Is it spiky? Is it steady state? Is it Gaussian uniform or cross on the timer? Tools jameter is just one example. I think that other ecosystems have similar solutions for that. But yes, you get other requirements. You get a kind of understanding of how the system will be slammed in the field, and then you imitate that in the testing environment. So the early phases is when you do all your design, you get all the information, you give your feedback, you try to see how you can get more observability. A big word is being used today observability, but it's important you start to see how you can trace the logs, the application logs or the system logs, how you can trace matrices in the system. All that is carried out in the design phase of the test.
That's correct. But most of the projects I have seen, right? Performance testers always treat as third class citizens, right?
Yeah.
So we really do not involve in high level meetings when it comes to architectural decisions or say, re architecting something to improve some performance. So they don't invite us in those meetings. So how you face that kind of environment in your projects? So how do we take care of this in the future going forward?
Well, I think that there is a change. It starts to change. I think that today we see that the entire again, not just performance testing, but the entire landscape of automation has changed. I think that when I started automation and again, that was twelve years ago. I think that back in the day the view was still like, okay, I'm going to take a few QA testers and they have some mediocre programming skills, and I'm going to pledge them into being automation developer. It's going to be good enough. But today we start not today, but in the last few years, I think we start to see the change that automation is a lot more technical than it used to be. There is these call list or low code and no code solutions, and they're great, of course. But there's still the more technical stuff. And I think that there is a change. And when we start to see the impact that performance has on user experience, so I think you all heard his numbers. What was his name? Jacob Nicholson. I think Nielsen. I don't remember his last name, but the heuristic is that anywhere between 100 milliseconds to 1000 milliseconds, the user is content one to 10 seconds. The user is tolerating and over 10 seconds the user is frustrated. So the impact that performance has on user experience users to vote with their dollars to the application that serves them better. And when management realized this, when management realized that performance is required, they start to make changes. So this is a change that I started to see. And I think that you as a performance engineer, you can bring up these heuristics. So management can understand why that's so important. You can bring up the empirical data. I think the empirical data is that for every 100 milliseconds of latency, there is a 15% to 20% drop in traffic. So when they realize that performance is that important, it's that crucial to their business. They'll make a change and they'll start having you as a performance engineer more involved in early decisions. Now, I'm not sure if the performance engineer is supposed to be too much involved in the architecture again, because they're not particularly as good as the DevOps engineer, for example, are in Kubernetes or as the DBA is proficient in Caching and engines and stuff like that. But they can be very highly involved in how to design the test and how to decide whether the changes are good for the application performance or they're not good for the application performance. I think this is the part that you should propagate as a performance engineer. This is how we're going to test. This is how we're going to put our ID to the ultimate test and how we make sure that we don't harm user experience. Got it.
So based on the skill set of any performance engineer, they should involve as need basis, mostly you are telling your thought is we have to involve more in our test design part.
Right.
Test design, test distribution analysis.
Test design and test infrastructure because you decentralized the effort. So it has become a testing infrastructure that you create.
Okay, so we have Sid joined us. Hi, Siddh. Thanks for joining. If you have any questions, please. Yeah.
Thanks, Navin, for admitting.
Hi.
Good morning.
Aladdin. So that was a nice explanation. And I do have few questions and a few concerns. So let me ask the questions first.
Like.
The centralized and decentralized part. So who is the decision maker? Whether it has to be centralized or decentralized? And what is our part in that taking addition.
Who'S is the decision maker? You said yes.
Who's going to be decision maker? Is that to be a performance manager or performance team, whether it has to go as a decentralized or centralized.
You mean who's going to make the decision of which model should be applied to a project?
Correct.
Okay, I'll answer it. Go on to your second question.
It's not a question, though. It's a concern. I do agree with Naveen because yes, there is. Though we are not having a knowledge like DevOps or architects, there is an Estee of us to involve in those kind of meetings to understand better of architect of the application or anything. So even though you are not taking a key role key active player, but there is a state of you to understand whether it may be Cuban at ease and what is the architecture in the starting of the project itself? So I feel that gives more inside of your app or application or microservice, whatever it may be to give the better knowledge what you are testing. Yes, I agree that you can design. You are the decision maker on designing your test designs, but before that I feel if anybody wants to design any test case or automation framework, anything you need to have better understanding of architecture level in and out, that's what I feel that you can comment on that.
Okay.
I'm going to stop with the comment. Of course it's not to say that performance engineers are not supposed to know anything about Kubernetes. I think that they should experiment with hands on and with Docker and with all of these stuff. And this knowledge can system a lot, and in some cases they can even come up with ideas how to solve bottlenecks. They can identify bottlenecks and come up with ideas to solve them. However, they are not as proficient because they are most specialized in performance testing. This is toxic opportunity cost. If you are specializing in one thing, it comes at the expense of other things and our time is finite. Desires are infinite. Of course we want to know everything, but our time is finite so we can invest so much in learning new stuff. However, because we are not as proficient as the Devil's engineers, we are not going to make these technical decisions to be high level Devils. Engineers are going to do that. Of course we are involved in that all the time. This is part of collaboration. This is part of the decentralized model. Everybody are involved. Okay, so the DevOps are involved in the load testing, performance testing and vice versa checks and balances kind of stuff. It's not that you are completely unaware of the architectural topics and answer your question, who decides which models will applied? And I'm going to refer to another thing that I do in my personal life. I'm one of the directors of Israel's drug tested Body building Federation WMBF, and one of the things that we have learned because we saw other federations that are not drug tested here in Israel. They're trying to do some drug tests to see if there's any performance enhancement drugs. And we realized that you have only two options. You either start as a drug tested competition or you don't. You can't just switch in the middle and change everything into being a drug test. I think it's the same case here. If you decided to decentralize, it is very difficult to change it somewhere in the future. Pretty much it's going to be centralized all the way. Unfortunately, however, if the project started as decentralized, it's easier to switch it to decentralized model, but I don't see any reason why I would like to do that, because the decentralized model actually relieves a lot of bottleneck and a lot of liabilities from everybody who are involved. So who makes this decision? I think that this is more a spontaneous decision that teams make, and gradually you can propagate that across the board. If you work in a single organization, slowly and steadily, all the projects will follow. If they see that one idea is better, if they see that the decentralized model is better than the centralized model, they will adopt this. Of course, it depends on the people who are involved. Some people are not comfortable with the decentralized model for some reason. Then it's going to be more difficult. So I don't think it's a decision made by authority. I think it's more spontaneous and self generated. So that's what I found about it. Now, on the contrary to that, if you're not working in a single organization, but you're more kind of a consultant and you work with several organizations. So I think you're going to experience a vast difference in the organizational culture of different organizations. And for some organizations, the decentralized model would be more suitable and for others it would be less suitable. But I think that ultimately the distance sized model will benefit. True.
Thanks for Eldad.
I agree the decentralized model has advantages. But if you think about from say, you are working for our client and say development is taking care of one company database is another company. Testing is another company, like a multi vendor environment. So this decentralized model right, when we follow, it is very stringent to implement in that environment, because if you want to run a test, right, you cannot just start your test because there are multiple vendors involved and somebody will say, okay, you cannot run the test or someone will say, okay, we are okay with the test. So even decentralized model has some disadvantages.
Correct.
So it has it to its own Con.
Of course, every model would have disadvantages and advantages. And then you're going to have to weigh them out one against the other. Are the advantages outlay the disadvantages. And let me give you a little things that we have experienced in the decentralized model. So one of the stakeholders run the test and he scaled up the test by adding more and more load agent machines. They turned out that these load agent machines were extremely expensive and it cost us a lot of money. So we gather together and we pointed out these problems and he realized that this is wrong. He can do the same test with less agents. Now it's all fine and it's running. So yes, you're going to have these mistakes sometimes and you're going to have some errors in a way. But ultimately, when people learn how to work with it and how to coordinate their efforts, they enjoy the benefits.
That's correct. Yes, I agree. Yes. Thank you.
Is there anything else you want to add? I think she wanted to add another thing is there anything else that you wanted to mention?
Yeah. True.
Thanks for clarifying that. And I still have the consent. I understanding that we as a performance engineers, look, forget about the testers. So nowadays everything is going as SRE cycle engineer. So where everybody has to adapt everything. Don't you think that we need to have a knowledge? What DevOps, what architects are going to change, even though as a performance center, you shouldn't have the good enough knowledge that. So let's say today Architect or DevOps made some changes to application and you have to design your test. You should be knowing that thing.
Right.
What they are changing. And how does FX as a performance test, right.
I agree. Yes. Yeah.
So that's what I was supporting. Navin, we need to not see, we necessarily not need to be giving a suggestion in architect level or design level, but if we involved into those kind of meetings, we will be aware of what is going on and how does it affect in terms of performance?
Absolutely. I agree with that. Again, I didn't say that you're not involved in architectural decisions. I said that your involvement is not as profound as the DevOps engineers, because they have probably more experience, more time to learn the stuff. You have more time to learn about performance testing practices, and they're not going to be as proficient in that as you are. So it's checks and balances. You are involved in all the stages of decision. You're involved in the architectural decisions, of course. And so that's pretty much it.
Hi Rakesh. Thanks for joining.
Hi, Nami. Thanks.
In decentralized testing. How you deal with the dependencies?
Define dependency, please. No.
I said how you deal with the dependencies? Like, for example, let's say if you're focusing on system A, system B, system C, like my entire business process involved system A to C journey.
You mean like a microservices architecture. Yeah.
Like a distributed architecture.
Distributed architecture.
Yeah. Okay. So let's say you have one server that is responsible for authentication and another server that is responsible for.
Something else.
Something.
Check out service. Yeah.
Exactly. Okay. Cool. So in some tests, you run the entire thing because you want to see things end to end in other tests. You actually want to rule some of these dependencies out. Okay. So for example, and actually, I have an article about this. Let's say that you have a bug in the authentication server and it's going to block the entire system. Right. So the solution to that is virtualization. So you're going to virtualize these microservices that you're dependent on, and then you're going to use mock data. So it's going to be the same in centralized and decentralized model. It's two or not too exclusive. You're going to have to set up the environment and the setting of the environment is the same thing. If you're centralized and decentralized, you're going to set up the environment in according to the need. If you need an environment of full end to end performance test, you're going to spin up all the servers. And if you have some, I would call it server level tests. This is the equivalent to unit test in code testing. So you're going to spin up on environment with virtualized servers or microservices. So I think this is the solution. Obviously, this only applies for the rest kind of restful services. When you have IoT services and stuff like that, you need to virtualize them in a different way. But there are currently good solutions for virtualization. And again, I think we have seen a boom in that in the last five years. They're really awesome products that you can search for to virtualize contain microservices and stuff like that. There are plenty of them.
Where we can create some stuff or something like that or where we can move the services. We can Mark the services, and we still need to have the environment to support into him.
Yes, of course. And this is part of the reason why the interpersonal communication is so important. You need the DevOps to understand your needs and you need to understand their needs. This is where it really becomes important. You need to really collaborate.
Have you thought about having the hybrid model combination of centralized and decentralized?
Good question. Good question. I think that when you start to have a really large company, I think that in some sense you're going to use this hybrid stuff. So let's say you have, like, ten different projects in your company. And so each project is going to have its own performance engineer, and they are going to work in a kind of centralized model. But these ten projects are actually the ten microservices, so they're probably going to be decentralized. It could happen in very large organizations because centralizing is good for small groups. It's an economic principle. Centralizing decision making is good in small groups, and decentralizing is good in big groups. So maybe you're going to have this hybrid. Okay. So the NFL is decentralized. But each football team in the NFL is centralized in a way. So yes, you could have a high grid in my company. We do something like that in some things. We do centralized model and other things. We do decentralized model. And I think that we do decentralized model for more complex, more complex projects. When you have a lot of microservices involvement and IoT stuff, this is where we typically do it.
I'm working kind of a hybrid model. So we have some maps which are running in the centralized model. And Microsoft, which I am working, is decentralized, but everything understandable will be.
Yeah, everybody is working on some model, but we do not know the name or we not identified it.
Actually.
You have to get some white paper. I think you have to come up with some framework and publish it as a white paper. Yeah.
I'm sorry. I couldn't hear you for a second. What was that?
No, I just want to know about the hybrid model, how it works. What are the drawbacks or will it bring both the advantages of centralized and decentralized so that it will create some fruitful environment?
Yeah. So I think it's because the hybrid model tends to be too intuitive, because again, as you mentioned, you do what happens? It's just emergent. It's not authoritative. Right. So you emerge to do some decentralized model in one project and centralized model in other projects. So the consequences that it's intuitive and you don't really understand what's better for each scenario. So I think that the disadvantage here is that when it's too intuitive, you don't have strict guidelines. You don't have strict rules. And again, if you could consider this as an advantage and a disadvantage, it's a disadvantage, because when there are no rules, you don't really know what's the next step, what's going to be the next part of the plan. And when you have strict rules, it's difficult for you to be flexible to make changes, to adapt to changes. It's the same as the difference between agile and waterfall. Waterfall has a disadvantage of being too rigid and not being able to change. But everybody knows what's the plan. Everybody know what to do in the next 3456 months. And Agile has more flexible rules. So you have more room for changes. But you don't always know what's the big picture plan usually you do, but it's not as clear. So again, it's the same way here. You can look at this as being an advantage in this advantage at the same time, depending on the context.
Yeah, we do have.
Okay.
As right. So okay. As will give us the big picture.
Correct.
So we have some quarterly.
Okay.
As we identify what these are objectives we are going to achieve, then the teams will work on the agile.
Correct.
So we do have a big picture, correct? Yeah.
You have a strategy, the big picture strategy. But the advancement in the strategy is very decentralized and very fluid. Again, this is the idea of having maybe centralized overall goal or overall strategy, but the way you try to achieve that is kind of decentralized in a way.
I got it.
I have a question.
Sorry.
How does this decentralized, centralized related with Agile like CACD? Which one do you think will fit if it's the latest, which one better? You think.
And see if I get the question right before I answer it. So you ask if the decentralized model is better fit for CI, CD or Agile? Is that the question?
No.
For Agile and CLCD. So which model you think would be fit? Better fit, whether it should be centralized or decentralized?
Yeah.
I think it really depends. First of all, how complex the project is. I think the CICD and Agile is not as part of the question. I think it's more about the first of all, the type of people working on the project. If you have people who are overly rigid and they like things by the book, maybe they would prefer a centralized model and vice versa. If you have people who are more creative and they like to experiment, then they would go for a decentralized model. And of course, the nature of the project itself. If it's a very complicated project, you might prefer the decentralized model. I wouldn't say simple, but a simpler project you might prefer to centralize mobile. Got it.
Makes sense.
Does that have a question?
Mine is not a question. Sorry, I've joined this conversation bit late. So my understanding and decentralized is something more. Selecting a model and approach to selecting tools. Approach model that is more specific to the project. And centralized is more like using the common practices and things like that.
Is that right?
I'm talking about the decentralized versus centralized. Is that my understandings? Correct me on decentralized console?
No, I'll go over it again just briefly. Sorry.
Okay.
So a centralized model is when the performance engineer. I'm sorry. I have a little bit of Beck on that. Execute and analyze the lowest results. Okay. So for example, you are the performance engineer. You run the locust by yourself. You're triggered to do that by some event, either you have a new version coming up or someone told you that you should run the locust or whatever reason. Then you analyze these results and you report them to whoever is made concern. The decentralized model is when you have stakeholders.
Okay.
So you have your DBA and you have your DevOps engineer and you have your back end developers and other people who are interested in Lo test or in the outcome of Lotus. They are taking initiative. They are executing Lotus by themselves. They analyze the result by themselves. You the performance engineer. You created the infrastructure that allowed them to do that.
Okay.
And it's not like you created this infrastructure and that's it. You're done constantly developed, constantly revised and deed. I'm sorry, I got bounced out. Do you hear me? Yes.
We can hear you. Yeah.
So centralized. You have one person or team, a shared entity who runs the lowest and analyze them and report. And in the decentralized model, you have people who take initiatives. There are different stakeholders. They run the low test, they execute them, then they analyze the results and the report is done more collaboratively.
Yeah.
Makes sense. But this depends upon the organization and their interest rate. Like, for example, in my organization, we run multiple projects and in some projects, the development team is really interested in performance, and some teams are not interested. Like taking.
Something that has been discussed. Yeah, the organizational culture or the people who are involved. I think it's better way to phrase it. It's the people. So the people who are involved in different projects are going to be the major factor of how it's going to be carried out.
So I would say we are running hybrid models. So some projects, like where those are taking initiative and they analyze the results and they work with us in tuning activities. And in some cases, as I said, we are in the test with them and we explain what we observe here.
Yeah.
More to be more precise, the performance engineers, they create the infrastructure. So you literally create a set of tools to execute the loads and to analyze the results. And you mentor everybody. Of course, you tell them, hey, this is how you do the analysis. And this is what they charge, what they mean. And this is how you execute them. And so on. And so on. I just wanted to mention, I think it was like two weeks ago that univin you posted. I saw it on LinkedIn. I saw it on other platform that you said too many clicks to run a loaded. Yeah. That was a good one. And I think there are three qualities to that short sentence. There are three qualities to that sentence. One, it's funny. Two, it's sad. And three, it's true. You need to click so many buttons to run a little bit. So you as a performance engineer, you really have to make sure that it doesn't happen. So your infrastructure has to be plain clear, easy to use as few clicks as possible, as fewer things to remember as possible. That's pretty much what you're going to be focused on.
I think you have to go with the CLA command line tools instead of UA based tools.
Yeah, I think so. Yeah.
Because I don't want to name the tool. You have to click at least ten to 15 buttons to start a Lotus. That's why I posted that.
Yeah, I know. I realized this was an unpleasant experience for you. Yes.
So any other topics you have mind to discuss? Collaboration?
Yeah. So collaboration. I think this is the moment we start talking about the human part, the interpersonal part. So I think that we need to really understand how to do it. How do you make the effort decentralized? Because you need to create an infrastructure that other people would be comfortable using. I think that again, I'm going to focus on the Jay Meter ecosystem, but I think the comment that I'm going to lay out was holding most other platforms. The first thing is to parameterize parameterize almost everything that you can and use clear names with a consistent format. Okay. So if you choose a snake case format or a Camel case format or whatever format that you happen to choose, be consistent and use long names in Jamaica. That's okay to use long names because long names signal the intention. People understand what it means. And if they want to change these parameters, they can do that comfortably. Second is, again, make sure that you have a good auditing. And again, there are plenty of tools that will do that for you. Plenty of cloud based tools where you can just clone a template of a test that was executed and then get it executed. So first of all, it is on the execution. You don't have to click a lot of buttons, just two buttons and that's it. You're up. And it also is on the analysis because you have good auditing auditing. You know what happened in history. You can go back and see past results. It could help a lot for you and for others. And when you do analysis, you need to make sure that you use tools that other people can use. For example, I really enjoy using the Jupyter notebook. I'm a Python developer, so I have this bias, but Jupyter notebooks are good for exploratory data analysis. So when exploratory data analysis is needed, you can use Jupyter notebooks to do that. And then you need to make sure how do you make it more accessible and approachable to other people. Okay. So read your markdown files or your markdown cells in the user notebook and use your progress bar. Make sure to give them a good experience. This is how you're going to use it. And they're going to thank you for that. So that's pretty much the guidelines that I would go with. Another thing that I would go with is I think that's for many performance engineers, the decentralized model feels kind of threatening because now other people are executing the tests of what is there for me? Job security stuff. But no, I don't think it takes anything away from the performance engineer. The performance engineer is now more focused on creating the infrastructure, and that's a lot of work. No, I don't think that anything is being taken away from the performance engineer. On the contrary, the performance engineer seems more responsibilities that way. Correct? Yeah.
Good thing you mentioned about Jupiter notebook recently. I started implementing. So whenever I give some presentation to the development team, right. So I just control enter. Right. So if you keep on pressing control enter, it will just execute that block and it will display the charts and it will compare with the previous builds. And then people ask, what are you doing then people are asking about how you implemented that. So it was a good learning for me as well to implement that idea. Also, there's another thing to check it out. It's called STREAMLET. I don't know. You would have heard about this LD. So there is a framework called Streamlit. So again, it is like a Jupitery notebook, but it's more UI wise. It is more advanced version.
Probably.
You can also check it out. Streamlit?
Yeah.
Streamlit is awesome for Dashboarding, and the technical details behind it are just amazing. It uses plastic behind the scenes. So you have this real server client kind of intercommunication and spin. It has been growing in popularity in Dashboarders because it's really convenient. It's a really good stuff. In Jupiter notebook, you can create a website out of it using other solutions like Bola and stuff like that. It's good, but it has some limitations. But again, Jupiter Notebook is awesome.
Yes. So I bet I tested the Streamlit when it was a beta testing. Now it has enhanced much. Actually, the new releases has more features.
Awesome.
I have a question as per collaboration.
So.
Do you made a built using Python or something? Any tool that will automate what work you are doing?
The Python part is used for the analysis. So what we do usually is we try to analyze logs, the application logs and then we try to find patterns in the logs and Python is very effective for that. So we do that in the Jupiter notebook because it's easier. You run a sell, you see a result. It looks good for you. You use it if you don't use something else. And again, we do it jointly. I very often take the lead back and developer in our team or the lead DBA and we do join Exploratory Data analysis, so I share my screen. I'll show them the Jupiter Notebook. I'll try a few stuff and then we come up with better ideas to explore data. The execution itself is done by J Meter and other SAS tools that they can easily execute and audit.
Thanks.
Are there any further questions or comments or.
I don't have any. So it's almost 1 hour. I think we can wind it up. Thank you, everyone.
Oh, there's another question.
Yes.
One small reminder and request, which Namin already did. So I did have a chance to discuss this centralization and decentralization with one of my architect in my previous organization. Just like Navin said, we are following it up like mixed models and this and that. But there is no article on that. I think it would be great. You take an initiative and write an article on that part that would be helpful for everyone. That's what I thought of.
Perhaps I will. Thanks for the offer.
You can counter or framework so that you can publish it will reach wider audience.
Yeah. Maybe we can do that.
Thank you. Thank you, everyone, for joining this week meat again this week's sponsor is Redline 13. So if you want to run a scalable load test, high scale load test, please check it out. Redline 13. Com and if you have any questions, you can reach Eldad in LinkedIn. So if you just search for Eldad, you can definitely get his profile and then you can touch base with him in LinkedIn. Is that fine? Linkedin is yours?
Absolutely. You can reach out to me for their responses.
Okay.
Sure.
Thank you, everyone and have a good weekend. Thank you.
Bye.
You let us meet next week. Have a good day.
Bye. Thank you, everybody. Thank you.
Thank you. Bye. See you.
Thank you. Bye.
